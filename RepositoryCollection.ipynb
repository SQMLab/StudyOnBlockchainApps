{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from github import Auth\n",
    "from github import Github\n",
    "import logging\n",
    "import json\n",
    "import pickle\n",
    "import os\n",
    "import time\n",
    "import shutil\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCESS_TOKEN = json.load(open(\"./config\"))[\"access_token\"]\n",
    "REPOSITORY_PATH = \"./Data/repository.csv\"\n",
    "github = Github(auth=Auth.Token(ACCESS_TOKEN))\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "logger = logging.getLogger()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Load or create the DataFrame\n",
    "\n",
    "def save_repositories(rawRepositoryList):\n",
    "    df = pd.read_csv(REPOSITORY_PATH, index_col='full_name') if os.path.exists(REPOSITORY_PATH) else  pd.DataFrame(columns=['full_name', 'id', 'name', 'is_fork', 'owner', 'owner_url',\n",
    "                           'repo_url', 'stars', 'forks', 'watchers', 'language', 'description',\n",
    "                           'open_issues', 'license_name', 'topics', 'default_branch',\n",
    "                           'pushed_at', 'created_at', 'updated_at', 'closed_issues']\n",
    "                 ).set_index('full_name')\n",
    "    repo_count = 0  # ✅ Fixed incorrect variable name\n",
    "    \n",
    "    new_rows = []  # ✅ Collect new rows to reduce DataFrame updates inside the loop\n",
    "    full_name_set = set(df.index)\n",
    "\n",
    "    for repo in rawRepositoryList:\n",
    "        #print(f'Parsing repo {repo_count}')\n",
    "        r = {\n",
    "            'id': [int(repo.id)],\n",
    "            'name': [repo.name],\n",
    "            'full_name': [repo.full_name],\n",
    "            'is_fork': [repo.fork],\n",
    "            'owner': [repo.owner.login],\n",
    "            'owner_url': [repo.owner.html_url],\n",
    "            'repo_url': [repo.html_url],\n",
    "            'stars': [int(repo.stargazers_count)],\n",
    "            'forks': [int(repo.forks_count)],\n",
    "            'watchers': [int(repo.watchers_count)],\n",
    "            'language': [getattr(repo, \"language\", None)],\n",
    "            'description': [getattr(repo, \"description\", None)],\n",
    "            'open_issues': [int(getattr(repo, \"open_issues_count\", 0))],\n",
    "            'license_name': [repo.license.name if repo.license else None],\n",
    "            'topics': None,\n",
    "            'default_branch': [repo.default_branch],\n",
    "            'pushed_at': [repo.pushed_at],\n",
    "            'created_at': [repo.created_at],\n",
    "            'updated_at': [repo.updated_at]\n",
    "        }\n",
    "        if repo.full_name not in full_name_set:\n",
    "            r['topics'] = [\", \".join(repo.get_topics())]\n",
    "            new_rows.append(pd.DataFrame(r).set_index('full_name'))\n",
    "            full_name_set.add(repo.full_name)\n",
    "\n",
    "        repo_count += 1\n",
    "    \n",
    "    if new_rows:\n",
    "        df = pd.concat([df] + new_rows)\n",
    "\n",
    "    print(f'Adding.. {len(new_rows)}/{repo_count}')\n",
    "    df.to_csv(REPOSITORY_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# key_words = [   # Crypto Coin\n",
    "#     \"bitcoin\",\n",
    "#     \"ethereum\",\n",
    "#     \"xrp\",\n",
    "#     \"tether\",\n",
    "#     \"bnb\",\n",
    "#     \"solana\",\n",
    "#     \"usdc\",\n",
    "#     \"dogecoin\",\n",
    "#     \"cardano\",\n",
    "#     \"tron\",\n",
    "#     \"chainlink\",\n",
    "#     \"sui\",\n",
    "#     \"stellar\",\n",
    "#     \"litecoin\",\n",
    "#     \"unus-sed-leo\",\n",
    "#     \"toncoin\",\n",
    "#     \"hedera\",\n",
    "#     \"hyperliquid\",\n",
    "#     \"polkadot\",\n",
    "#     \"bitcoin-cash\",\n",
    "#     \"ethena-usde\",\n",
    "#     \"bitget-token\",\n",
    "#     \"dai\",\n",
    "#     \"uniswap\",\n",
    "#     \"monero\",\n",
    "#     \"near-protocol\",\n",
    "#     \"pepe\",\n",
    "#     \"bittensor\",\n",
    "#     \"aave\",\n",
    "#     \"aptos\",\n",
    "#     \"ethereum-classic\",\n",
    "#     \"okb\",\n",
    "#     \"kaspa\",\n",
    "#     \"vechain\",\n",
    "#     \"pol-prev-matic\",  \n",
    "#     \"sonic-prev-ftm\",\n",
    "#     \"algorand\",\n",
    "#     \"filecoin\",\n",
    "#     \"first-digital-usd\",\n",
    "#     \"gatetoken\",\n",
    "#     \"kucoin-token\",\n",
    "#     \"lido-dao\",\n",
    "#     \"ethena\",\n",
    "#     \"xdc-network\",\n",
    "#     \"worldcoin\",\n",
    "#     \"sei\",\n",
    "#     \"jasmycoin\",\n",
    "#     \"ethereum-name-service\",\n",
    "#     \"jito\",\n",
    "#     \"floki\",\n",
    "#     \"tezos\",\n",
    "#     \"nexo\",\n",
    "#     \"berachain\",\n",
    "#     \"iota\",\n",
    "#     \"neo\",\n",
    "#     \"tether-gold\",\n",
    "#     \"bitcoin-sv\",\n",
    "#     \"spx6900\",\n",
    "#     \"dogwifhat\",\n",
    "\n",
    "#     #permissioned Blockchain\n",
    "#     \"hyperledger-fabric\",\n",
    "#     \"hyperledger-sawtooth\",\n",
    "#     \"hyperledger-iroha\",\n",
    "#     \"hyperledger-besu\",\n",
    "#     \"corda\",\n",
    "#     \"quorum\",\n",
    "#     \"multichain\",\n",
    "#     \"enterprise-blockchain\",\n",
    "#     \"consortium-blockchain\",\n",
    "#     \"ibm-blockchain\",\n",
    "\n",
    "#     #Popular Blockchain keywords\n",
    "#     \"blockchain\",\n",
    "#     \"smart-contracts\",\n",
    "#     \"solidity\",\n",
    "#     \"dapp\",\n",
    "#     \"ethereum\",\n",
    "#     \"web3\",\n",
    "#     \"cryptocurrency\",\n",
    "#     \"defi\",\n",
    "#     \"nft\",\n",
    "#     \"distributed-ledger\",\n",
    "#     \"decentralized-network\"\n",
    "#   ]\n",
    "\n",
    "#dappradar\n",
    "key_words = [\n",
    "    \"KAI-CHING\",\n",
    "    \"World of Dypians\",\n",
    "    \"UXUY\",\n",
    "    \"Jupiter Exchange\",\n",
    "    \"Pixudi\",\n",
    "    \"Tevi\",\n",
    "    \"Age of Dino\",\n",
    "    \"SERAPH: In The Darkness\",\n",
    "    \"Chingari\",\n",
    "    \"Revox | ReadON\",\n",
    "    \"KGeN\",\n",
    "    \"Alliance Games\",\n",
    "    \"Alaya AI\",\n",
    "    \"Dmail Network\",\n",
    "    \"Moonveil\",\n",
    "    \"Alien Worlds\",\n",
    "    \"PlayEmber\",\n",
    "    \"Sweat Economy\",\n",
    "    \"ZetaHub\",\n",
    "    \"ChainArena - PentagonGames EXP\",\n",
    "    \"Axie Infinity\",\n",
    "    \"BoomLand\",\n",
    "    \"GombleGames\",\n",
    "    \"Evermoon\",\n",
    "    \"Nine Chronicles\",\n",
    "    \"Slime Revolution\",\n",
    "    \"The Lost Glitches\",\n",
    "    \"Immortal Rising 2\",\n",
    "    \"Yuliverse\",\n",
    "    \"Apeiron\",\n",
    "    \"AtomicAssets\",\n",
    "    \"Growfitter\",\n",
    "    \"Redbrick\",\n",
    "    \"KeitoKun\",\n",
    "    \"PancakeSwap V2\",\n",
    "    \"Jumper Exchange\",\n",
    "    \"Super Champs HQ\",\n",
    "    \"Karat Galaxy\",\n",
    "    \"FishWar\",\n",
    "    \"Harvest Moon ~ Meteor Wallet\",\n",
    "    \"OpenPad AI\",\n",
    "    \"IN - match3\",\n",
    "    \"Yomi Block Puzzle\",\n",
    "    \"SendingMe\",\n",
    "    \"ERAGON\",\n",
    "    \"1inch Network\",\n",
    "    \"QORPO WORLD\",\n",
    "    \"PancakeSwap V3\",\n",
    "    \"motoDEX\",\n",
    "    \"Sol Incinerator\",\n",
    "    \"QuickSwap\",\n",
    "    \"Dragon Slither\",\n",
    "    \"UneMeta\",\n",
    "    \"Galxe\",\n",
    "    \"SuperWalk\",\n",
    "    \"GOAT Gaming\",\n",
    "    \"Taco Studios\",\n",
    "    \"OpenChat\",\n",
    "    \"Don't FOMO\",\n",
    "    \"MomoAI(MetaOasis)\",\n",
    "    \"SpinCity\",\n",
    "    \"IceCreamSwap\",\n",
    "    \"Sunflower Land\",\n",
    "    \"NFPrompt\",\n",
    "    \"Piratopia\",\n",
    "    \"Flappy Core\",\n",
    "    \"Stargate\",\n",
    "    \"HunnyPlay\",\n",
    "    \"xPortal\",\n",
    "    \"WORLD3\",\n",
    "    \"Unipoly Lottery & Web3 Games\",\n",
    "    \"Wild West Shooting\",\n",
    "    \"Core Tetris\",\n",
    "    \"NFTMining - By Pentagon Games\",\n",
    "    \"Archer Hunter\",\n",
    "    \"PLAYZAP GAMES\"\n",
    "]\n",
    "\n",
    "# languages = [\n",
    "#     \"Solidity\", \"Rust\", \"Go\", \"JavaScript\", \"TypeScript\", \n",
    "#     \"Python\", \"C++\", \"Java\", \"C#\", \"Kotlin\", \"\"\n",
    "# ]\n",
    "languages = [ \"\"]\n",
    "\n",
    "for key in set(key_words):\n",
    "    for language in languages:\n",
    "      query_language = f'language:{language}' if language else ''\n",
    "      #query = f\"topic:{key} archived:false created:>2021-03-06 pushed:>2024-02-21 size:>1 stars:>4 forks:>4 is:public\"\n",
    "      query = f\"(topic:{key} OR {key} in:name OR {key} in:description OR {key} in:readme) {query_language} archived:false created:>2021-03-06 pushed:>2024-02-21 size:>0 stars:>4 forks:>4 is:public\"\n",
    "      print(f\"Fetching Repositories..  {query}\")\n",
    "      repositories = github.search_repositories(query=query, sort='stars', order=\"desc\")\n",
    "      print(f\"Storing Repositories..  {query}\")\n",
    "      save_repositories(repositories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# df = pd.read_csv(REPOSITORY_PATH, index_col='full_name')\n",
    "# i = 0\n",
    "# for index, row in df.iterrows():\n",
    "#     if i % 10 == 0:\n",
    "#             print(f'fetching issues for {index} : {i+1}')\n",
    "#     if 'closed_issues' not in df.columns or  pd.isna(df.at[index, 'closed_issues']):\n",
    "#         repo = github.get_repo(row['id'])\n",
    "#         closed_issues = repo.get_issues(state='closed')\n",
    "#         closed_issue_count = closed_issues.totalCount\n",
    "#         #closed_issue_count = sum(1 for issue in closed_issues if not issue.pull_request)\n",
    "#         df.at[index, 'closed_issues'] = int(closed_issue_count)\n",
    "#         if i % 10 == 0:\n",
    "#             df.to_csv(REPOSITORY_PATH)\n",
    "#     i += 1\n",
    "# df.to_csv(REPOSITORY_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(REPOSITORY_PATH, index_col='full_name')\n",
    "# df['closed_issues'] = df['closed_issues'].astype(int)\n",
    "# df.to_csv(REPOSITORY_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df = pd.read_csv(REPOSITORY_PATH, index_col='full_name')\n",
    "\n",
    "\n",
    "# df = df.sample(frac=1, random_state=42)\n",
    "\n",
    "# split_ratio = 0.5\n",
    "# split_index = int(len(df) * split_ratio)\n",
    "\n",
    "# df1 = df[:split_index]\n",
    "# df2 = df[split_index:]\n",
    "\n",
    "# # Save to new CSV files\n",
    "# df1.to_csv(\"./Data/repository-part1.csv\")\n",
    "# df2.to_csv(\"./Data/repository-part2.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# READ_ME_PATH = \"../bc-readme\"\n",
    "# os.makedirs(READ_ME_PATH, exist_ok=True)\n",
    "# df = pd.read_csv(REPOSITORY_PATH, index_col='full_name')\n",
    "# for index, row in df.iterrows():\n",
    "#     repo = github.get_repo(row['id'])\n",
    "#     readme = repo.get_readme()\n",
    "#     readme_content = readme.decoded_content.decode(\"utf-8\")\n",
    "#     closed_issues = repo.get_issues(state='closed')\n",
    "#     closed_issue_count = sum(1 for issue in closed_issues if not issue.pull_request)\n",
    "#     df.at[index, 'closed_issues'] = int(closed_issue_count)\n",
    "#     df.at[index, 'readme'] = readme_content\n",
    "#     with open(READ_ME_PATH + '/' + index.replace('/', '--') + '--' +  readme.name, \"w\") as readme_file:\n",
    "#         readme_file.write(readme_content)\n",
    "# df.to_csv('./Data/repositoryv2.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
